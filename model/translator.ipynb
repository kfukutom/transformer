{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from transformer import Transformer\n",
    "import torch\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model on preprocessed data:\n",
      "[[-1.22474487  0.26726124  0.        ]\n",
      " [ 1.22474487 -1.33630621 -1.22474487]\n",
      " [ 0.          1.06904497  1.22474487]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def preprocess_data(func):\n",
    "    \"\"\"\n",
    "    A decorator for preprocessing data. It normalizes and scales the input data.\n",
    "    \"\"\"\n",
    "    def wrapper(data):\n",
    "        # Convert data to a numpy array for ease of manipulation\n",
    "        data_array = np.array(data)\n",
    "        \n",
    "        # Normalize data to have mean = 0\n",
    "        normalized_data = data_array - np.mean(data_array, axis=0)\n",
    "        \n",
    "        # Scale data to have std deviation = 1\n",
    "        scaled_data = normalized_data / np.std(normalized_data, axis=0)\n",
    "        \n",
    "        # Call the original function with the preprocessed data\n",
    "        return func(scaled_data)\n",
    "    \n",
    "    return wrapper\n",
    "\n",
    "@preprocess_data\n",
    "def train_model(data):\n",
    "    \"\"\"\n",
    "    Simulate model training on preprocessed data.\n",
    "    \"\"\"\n",
    "    print(\"Training model on preprocessed data:\")\n",
    "    print(data)\n",
    "\n",
    "# Example data - list of lists (each inner list could represent a data point)\n",
    "data = [\n",
    "    [10, 200, 3000],\n",
    "    [20, 180, 2900],\n",
    "    [15, 210, 3100],\n",
    "]\n",
    "\n",
    "train_model(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q\n",
      " [[ 3.49091629e-04 -2.36564313e-01  3.93158170e-02  4.83598993e-01\n",
      "  -2.29602947e-01 -7.35765196e-01  1.07824883e+00  5.66690295e-01]\n",
      " [ 1.23051533e+00 -4.33139369e-01  1.18632675e-01 -6.35105072e-01\n",
      "   7.27291883e-01  6.83922365e-01  1.04503623e+00 -4.42515101e-01]\n",
      " [ 4.92282258e-01  2.87076127e-02  1.67373830e+00  3.22394141e-01\n",
      "  -3.24316367e-01 -1.02331742e+00  3.93354903e-01 -3.58839411e-01]\n",
      " [ 4.26648044e-02 -1.41740165e+00  1.44892517e+00  9.75861054e-01\n",
      "  -1.70714505e+00  3.56247539e-01 -1.43150950e-01 -5.42089755e-01]]\n",
      "K\n",
      " [[ 0.81576652  0.13905938 -0.04025353  1.2167816   0.61761556  0.34638913\n",
      "   0.20713831  0.63918787]\n",
      " [-1.28025409 -1.94942609  0.69737744  1.21971493 -0.24545391 -0.81391399\n",
      "  -1.0323937   1.31551563]\n",
      " [-0.25614235 -0.26647644 -0.11443513  0.51109189 -0.63809394 -0.20404782\n",
      "   0.43742648  0.64823154]\n",
      " [ 0.53449474  1.55257826  1.20347173  0.19976405  0.31349574 -1.20578455\n",
      "   1.2722732   0.18830745]]\n",
      "V\n",
      " [[ 0.96138538  0.22132426 -0.23674417  0.29412005  0.49256353 -0.6933207\n",
      "  -1.83949971  0.58269026]\n",
      " [ 0.46387754  0.55195751  0.39193237 -0.50763452 -0.80990531  0.44745248\n",
      "   0.81561098 -0.76182857]\n",
      " [ 1.06759503  0.82331972 -0.05142112  0.29376034  0.50508403 -1.57696986\n",
      "   1.47153952  1.18812361]\n",
      " [-1.20318194  1.57014292 -0.70935905  0.42224968  1.68504329 -0.70751418\n",
      "  -1.66388645 -1.43897699]]\n"
     ]
    }
   ],
   "source": [
    "L, d_k, d_v = 4, 8, 8\n",
    "q = np.random.randn(L, d_k)\n",
    "k = np.random.randn(L, d_k)\n",
    "v = np.random.randn(L, d_v)\n",
    "\n",
    "print(\"Q\\n\", q) # queue\n",
    "print(\"K\\n\", k) # key\n",
    "print(\"V\\n\", v) # value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.74314083,  1.36550776,  1.44125445,  2.070557  ],\n",
       "       [ 0.78572838, -3.81910946, -0.97129758,  0.6507037 ],\n",
       "       [ 0.02783304,  0.90858764,  0.19469716,  3.95150388],\n",
       "       [-0.34032137,  4.47294916,  1.3023323 , -1.48808756]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# self attention matrix will have every word look at every other word in the sentence\n",
    "# 4 cross 4 matrix for example \"My name is Ken\" len(4)\n",
    "np.matmul(q, k.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6061670609807732, 0.6805783024159235, 0.4522523984219733)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.var(), k.var(), np.matmul(q, k.T).var()\n",
    "scaled = np.matmul(q, k.T) / math.sqrt(d_k)\n",
    "q.var(), k.var(), scaled.var() #minimize skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.26273996,  0.4827799 ,  0.5095604 ,  0.73205245],\n",
       "       [ 0.27779693, -1.3502591 , -0.34340555,  0.2300585 ],\n",
       "       [ 0.00984046,  0.32123424,  0.06883584,  1.3970676 ],\n",
       "       [-0.12032177,  1.58142634,  0.460444  , -0.5261184 ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masking ##\n",
    "- This is to ensure words don't get context from words generated in the future\n",
    "- Not required in the encoders, but required in the decoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = np.tril(np.ones( (L, L) )) # triangular matrix\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0., -inf, -inf, -inf],\n",
       "       [  0.,   0., -inf, -inf],\n",
       "       [  0.,   0.,   0., -inf],\n",
       "       [  0.,   0.,   0.,   0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask[mask==0] = -np.infty\n",
    "mask[mask==1] = 0\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.26273996,        -inf,        -inf,        -inf],\n",
       "       [ 0.27779693, -1.3502591 ,        -inf,        -inf],\n",
       "       [ 0.00984046,  0.32123424,  0.06883584,        -inf],\n",
       "       [-0.12032177,  1.58142634,  0.460444  , -0.5261184 ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled + mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# softmask, convert a vector into a probability distribution\n",
    "def softmax(x): \n",
    "    return (np.exp(x).T / np.sum(np.exp(x), axis=1)).T\n",
    "attention = softmax(scaled + mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.83590316, 0.16409684, 0.        , 0.        ],\n",
       "       [0.29187731, 0.3985079 , 0.30961479, 0.        ],\n",
       "       [0.11188965, 0.61354967, 0.1999923 , 0.07456837]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.96138538,  0.22132426, -0.23674417,  0.29412005,  0.49256353,\n",
       "        -0.6933207 , -1.83949971,  0.58269026],\n",
       "       [ 0.87974592,  0.27558013, -0.13358034,  0.16255466,  0.27883251,\n",
       "        -0.50612343, -1.40380444,  0.36205897],\n",
       "       [ 0.79600866,  0.53947092,  0.07116715, -0.02549685, -0.02260406,\n",
       "        -0.51230443,  0.24372959,  0.23434001],\n",
       "       [ 0.51597246,  0.64515786,  0.15080117, -0.18831373, -0.21514052,\n",
       "        -0.17118111,  0.46482014, -0.27190926]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_v = np.matmul(attention, v)\n",
    "new_v\n",
    "# this new matricies better encapsulates the context of the masked words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New V\n",
      " [[ 0.19163855  0.87287014 -0.18504568  0.1390592   0.55102905 -0.64106133\n",
      "  -0.31220246 -0.22374355]\n",
      " [ 0.17825615  0.84443695 -0.32144608  0.2809344   0.82301804 -0.79170901\n",
      "  -0.92112393 -0.11179227]\n",
      " [-0.28130066  1.09487197 -0.34943714  0.21578155  0.89760055 -0.61749764\n",
      "  -0.7842327  -0.66736491]\n",
      " [ 0.51597246  0.64515786  0.15080117 -0.18831373 -0.21514052 -0.17118111\n",
      "   0.46482014 -0.27190926]]\n",
      "Attention\n",
      " [[1.         0.         0.         0.        ]\n",
      " [0.83590316 0.16409684 0.         0.        ]\n",
      " [0.29187731 0.3985079  0.30961479 0.        ]\n",
      " [0.11188965 0.61354967 0.1999923  0.07456837]]\n"
     ]
    }
   ],
   "source": [
    "# MASK is set to true when we are decoding\n",
    "def scaled_dot_product_attention(q, k, v, mask=None):\n",
    "    d_k = q.shape[-1]\n",
    "    scaled = np.matmul(q, k.T) / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scaled = scaled + mask\n",
    "    attention = softmax(scaled)\n",
    "    out = np.matmul(attention, v) # vector\n",
    "    return out, attention\n",
    "\n",
    "\"\"\"print(\"Q\\n\", q) # queue\n",
    "print(\"K\\n\", k) # key\n",
    "print(\"V\\n\", v) # value\"\"\"\n",
    "#apply scaled product def\n",
    "values, attnetion = scaled_dot_product_attention(q, k, v, mask=None)\n",
    "print(\"New V\\n\", values)\n",
    "print(\"Attention\\n\", attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn  \n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 4 # my name is ken\n",
    "batch_size = 1\n",
    "input_dim = 512\n",
    "d_model = 512\n",
    "x = torch.randn( (batch_size, sequence_length, input_dim) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 1536])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()\n",
    "qkv_layer = nn.Linear(input_dim, 3 * d_model)\n",
    "qkv = qkv_layer(x)\n",
    "qkv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "y_val = torch.histc(qkv, bins=200, min=-3, max=3)\n",
    "x_val = np.arange(-1, 1, 0.01) * 3\n",
    "plt.bar(x_val, y_val, align=\"center\", color=[\"forestgreen\"])\n",
    "plt.title(\"qkv distribution\")\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sampling from a random normal distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 192])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_heads = 8\n",
    "head_dim = d_model // num_heads\n",
    "qkv = qkv.reshape(batch_size, sequence_length, num_heads, 3 * head_dim)\n",
    "qkv.shape\n",
    "\n",
    "qkv = qkv.permute(0, 2, 1, 3)\n",
    "qkv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 8, 4, 64]),\n",
       " torch.Size([1, 8, 4, 64]),\n",
       " torch.Size([1, 8, 4, 64]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q, k, v = qkv.chunk(3, dim=-1)\n",
    "q.shape, k.shape, v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 4])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_k = q.size()[-1]\n",
    "# -2 == last two attrs/dimensions\n",
    "scaled = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g4/ykwfgyl55t7dfzv_zc3dcshh0000gn/T/ipykernel_1292/4066560417.py:1: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3641.)\n",
      "  k.T.shape\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf],\n",
       "        [0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.T.shape\n",
    "mask = torch.full(scaled.size(), float('-inf'))\n",
    "mask = torch.triu(mask, diagonal=1)\n",
    "mask[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2979,    -inf,    -inf,    -inf],\n",
       "        [ 0.0806, -0.0394,    -inf,    -inf],\n",
       "        [ 0.4009, -0.0070,  0.4119,    -inf],\n",
       "        [-0.4489, -0.1323,  0.0221, -0.0980]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(scaled + mask)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled += mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5300, 0.4700, 0.0000, 0.0000],\n",
       "        [0.3737, 0.2485, 0.3778, 0.0000],\n",
       "        [0.1854, 0.2544, 0.2969, 0.2633]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention = F.softmax(scaled, dim=-1)\n",
    "attention.shape\n",
    "attention[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 64])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = torch.matmul(attention, v)\n",
    "values.shape #much more context aware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# updated function\n",
    "def scaled_dot_product(q, k, v, mask=None):\n",
    "    d_k = q.size()[-1]\n",
    "    scaled = torch.matmul(q, k.transpose(-1, -2) / math.sqrt(d_k))\n",
    "    if mask is not None:\n",
    "        scaled += mask\n",
    "    attention = F.softmax(scaled, dim=-1)\n",
    "    values = torch.matmul(attention, v)\n",
    "    return values, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "values, attention = scaled_dot_product(q, k, v, mask=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 8, 4, 4]), torch.Size([1, 8, 4, 64]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention.shape, values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2350, 0.2686, 0.1471, 0.3492],\n",
       "        [0.2718, 0.2411, 0.1734, 0.3137],\n",
       "        [0.2936, 0.1952, 0.2968, 0.2144],\n",
       "        [0.1854, 0.2544, 0.2969, 0.2633]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 64])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 512])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = values.reshape(batch_size, sequence_length, num_heads * head_dim)\n",
    "values.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 4, 512]),\n",
       " tensor([[[ 0.1173, -0.1710,  0.0064,  ..., -0.1207,  0.3013,  0.1639],\n",
       "          [ 0.0469,  0.0930,  0.0426,  ..., -0.2752, -0.1506,  0.0289],\n",
       "          [ 0.1419, -0.0419, -0.0672,  ..., -0.1362,  0.0857,  0.1898],\n",
       "          [ 0.0183,  0.0776, -0.0284,  ..., -0.2607,  0.1579, -0.0055]]],\n",
       "        grad_fn=<ViewBackward0>))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_layer = nn.Linear(d_model, d_model)\n",
    "out = linear_layer(values)\n",
    "out.shape, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, input_dim, d_model, num_heads):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_model // num_heads\n",
    "        self.qkv_layer = nn.Linear(input_dim, 3 * d_model)\n",
    "        self.linear_layer = nn.Linear(d_model, d_model)\n",
    "    \n",
    "    def forward(self, x, mask=None):\n",
    "        batch_size, sequence_length, input_dim = x.size()\n",
    "        print(f\"x.size(): {x.size()}\")\n",
    "        qkv = self.qkv_layer(x)\n",
    "        print(f\"qkv.size(): {qkv.size()}\")\n",
    "        qkv = qkv.reshape(batch_size, sequence_length, self.num_heads, 3 * self.head_dim)\n",
    "        print(f\"qkv.size(): {qkv.size()}\")\n",
    "        qkv = qkv.permute(0, 2, 1, 3)\n",
    "        print(f\"qkv.size(): {qkv.size()}\")\n",
    "        q, k, v = qkv.chunk(3, dim=-1)\n",
    "        print(f\"q size: {q.size()}, k size: {k.size()}, v size: {v.size()}\")\n",
    "        values, attention = scaled_dot_product(q, k, v, mask)\n",
    "        print(f\"value.size(): {values.size()}, attention.size(): {attention.size()}\")\n",
    "        values = values.reshape(batch_size, sequence_length, self.num_heads * self.head_dim)\n",
    "        print(f\"values.size(): {values.size()}\")\n",
    "        out = self.linear_layer(values)\n",
    "        print(f\"out.size(): {out.size()}\")\n",
    "        return out # eof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.size(): torch.Size([30, 5, 1024])\n",
      "qkv.size(): torch.Size([30, 5, 1536])\n",
      "qkv.size(): torch.Size([30, 5, 8, 192])\n",
      "qkv.size(): torch.Size([30, 8, 5, 192])\n",
      "q size: torch.Size([30, 8, 5, 64]), k size: torch.Size([30, 8, 5, 64]), v size: torch.Size([30, 8, 5, 64])\n",
      "value.size(): torch.Size([30, 8, 5, 64]), attention.size(): torch.Size([30, 8, 5, 5])\n",
      "values.size(): torch.Size([30, 5, 512])\n",
      "out.size(): torch.Size([30, 5, 512])\n"
     ]
    }
   ],
   "source": [
    "input_dim = 1024\n",
    "d_model = 512\n",
    "num_heads = 8\n",
    "\n",
    "batch_size = 30\n",
    "sequence_length = 5\n",
    "x = torch.randn( (batch_size, sequence_length, input_dim))\n",
    "\n",
    "model = MultiHeadAttention(input_dim, d_model, num_heads)\n",
    "out = model.forward(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
